{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "979923b5-0493-4768-ad1a-06db54f0bc7a",
   "metadata": {},
   "source": [
    "# Final Project Notebook\n",
    "\n",
    "DS 5001 Exploratory Text Analytics | Spring 2024"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7046f57f-12ed-4259-be3d-60cb67b8d044",
   "metadata": {},
   "source": [
    "# Metadata\n",
    "\n",
    "- Full Name: Michael Vaden\n",
    "- Userid: mtv2eva\n",
    "- GitHub Repo URL: https://github.com/mtvaden1/Text_Analytics_Final_Project\n",
    "- UVA Box URL: https://virginia.box.com/s/x0gai3x6ulfcrp13bkb9cklt81sij13k"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57acd11d-eb04-4bcc-b115-f205f367de49",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "The goal of the final project is for you to create a **digital analytical edition** of a corpus using the tools, practices, and perspectives youâ€™ve learning in this course. You will select a corpus that has already been digitized and transcribed, parse that into an F-compliant set of tables, and then generate and visualize the results of a series of fitted models. You will also draw some tentative conclusions regarding the linguistic, cultural, psychological, or historical features represented by your corpus. The point of the exercise is to have you work with a corpus through the entire pipeline from ingestion to interpretation. \n",
    "\n",
    "Specifically, you will acquire a collection of long-form texts and perform the following operations:\n",
    "\n",
    "- **Convert** the collection from their source formats (F0) into a set of tables that conform to the Standard Text Analytic Data Model (F2).\n",
    "- **Annotate** these tables with statistical and linguistic features using NLP libraries such as NLTK (F3).\n",
    "- **Produce** a vector representation of the corpus to generate TFIDF values to add to the TOKEN (aka CORPUS) and VOCAB tables (F4).\n",
    "- **Model** the annotated and vectorized model with tables and features derived from the application of unsupervised methods, including PCA, LDA, and word2vec (F5).\n",
    "- **Explore** your results using statistical and visual methods.\n",
    "- **Present** conclusions about patterns observed in the corpus by means of these operations.\n",
    "\n",
    "When you are finished, you will make the results of your work available in GitHub (for code) and UVA Box (for data). You will submit to Gradescope (via Canvas) a PDF version of a Jupyter notebook that contains the information listed below.\n",
    "\n",
    "# Some Details\n",
    "\n",
    "- Please fill out your answers in each task below by editing the markdown cell. \n",
    "- Replace text that asks you to insert something with the thing, i.e. replace `(INSERT IMAGE HERE)` with an image element, e.g. `![](image.png)`.\n",
    "- For URLs, just paste the raw URL directly into the text area. Don't worry about providing link labels using `[label](link)`.\n",
    "- Please do not alter the structure of the document or cell, i.e. the bulleted lists. \n",
    "- You may add explanatory paragraphs below the bulleted lists.\n",
    "- Please name your tables as they are named in each task below.\n",
    "- Tasks are indicated by headers with point values in parentheses."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "568b6d68-e039-4612-858b-29510eeb5365",
   "metadata": {},
   "source": [
    "# Raw Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb0889de-cd53-4aa5-80b2-a2a39060776a",
   "metadata": {},
   "source": [
    "## Source Description (1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa9e395a-4b0b-4ba3-9112-80c733998dbe",
   "metadata": {},
   "source": [
    "Provide a brief description of your source material, including its provenance and content. Tell us where you found it and what kind of content it contains.\n",
    "\n",
    "*For this project, I wanted to use various song lyrics as my corpus. Specifically, I found 6 playlists on Spotify that corresponded to each decade ranging from the 70s to 2020s. These playlists are authored by Spotify, are tailored to my individual listening preferences, and contain the top 150 songs from each decade which Spotify recommends that I listen to. Using the Spotify API, I was able to query each of these playlists and songs (900 songs in total) to get the song title, artist, genre, and Spotify-specific metadata ranging from features such as key and time signature to popularity and danceability. After getting the song title and artist from each decade playlist, I then leveraged the Genius API to query for the song's lyrics. Although the Genius API is somewhat unreliable, occasionally returning the wrong lyrics, lyrics in another language, or no lyrics at all, it performs the intended task with a high enough success rate to get proper lyrics for most of the songs from each decade playlist. Finally, once I had all of the song features, metadata, and lyrics, I aggregated all of these to be able to compute my core tables and begin my advanced analysis.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89b507c1-6dc2-44f7-b74c-790d84a48e8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Source Features (1)\n",
    "\n",
    "Add values for the following items. (Do this for all following bulleted lists.)\n",
    "\n",
    "- Source URL: https://developer.spotify.com/documentation/web-api\n",
    "- UVA Box URL: https://virginia.box.com/s/ceqzkn1v5tps305w5pud7m2ndmvis51j\n",
    "- Number of raw documents: **6**\n",
    "- Total size of raw documents (e.g. in MB): **1.029**\n",
    "- File format(s), e.g. XML, plaintext, etc.: **txt**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "590e81b1-9f70-47b5-bb25-49be4e76b98b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Source Document Structure (1)\n",
    "\n",
    "Provide a brief description of the internal structure of each document. That, describe the typical elements found in document and their relation to each other. For example, a corpus of letters might be described as having a date, an addressee, a salutation, a set of content paragraphs, and closing. If they are various structures, state that.\n",
    "\n",
    "**Each of the decade .txt files, after being parsed from the lyrics of the song from the Genius API, has the same structure. Each has the header in the style of [Trackname: x] [Artist: y], which was manually inserted by me. After this, The song lyrics appear in stanzas (similar to paragraphs), but without periods. Rather, each stanza is filled with lines, which have sentence-like structure. Each of these lines simply breaks to a new line to signify that it ends. There is an empty line before and after each header, with the header dictating the end of the previous song's lyrics and the beginning of the next song's lyrics.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10ec4c9f-e101-46fe-ac59-a35a1b148a4b",
   "metadata": {},
   "source": [
    "# Parsed and Annotated Data\n",
    "\n",
    "Parse the raw data into the three core tables of your addition: the `LIB`, `CORPUS`, and `VOCAB` tables.\n",
    "\n",
    "These tables will be stored as CSV files with header rows.\n",
    "\n",
    "You may consider using `|` as a delimitter.\n",
    "\n",
    "Provide the following information for each."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9d05ce4-ac5c-43ea-a07b-c4626338f80e",
   "metadata": {},
   "source": [
    "## LIB (2)\n",
    "\n",
    "The source documents the corpus comprises. These may be books, plays, newspaper articles, abstracts, blog posts, etc. \n",
    "\n",
    "Note that these are *not* documents in the sense used to describe a bag-of-words representation of a text, e.g. chapter.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/gyo9hh8fuyagoj9wqjuxgvu55d46bgl6\n",
    "- GitHub URL for notebook used to create: https://github.com/mtvaden1/Text_Analytics_Final_Project/blob/main/Load_Song_Corpus.ipynb\n",
    "- Delimitter: **,**\n",
    "- Number of observations: **6**\n",
    "- List of features, including at least three that may be used for model summarization (e.g. date, author, etc.):\n",
    "\n",
    "**['Decade', 'danceability', 'energy', 'loudness', 'speechiness',\n",
    "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
    "       'source_file_path', 'song_regex', 'document_length']**\n",
    "\n",
    "- Average length of each document in characters: \n",
    "\n",
    "**(Decade, document_length): (70s, 127933), (80s, 151152), (90s, 174393), (2000s, 216931), (2010s, 195291), (2020s, 212348)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "304204a5-00be-46ad-b98b-0d10a9c8ca4b",
   "metadata": {},
   "source": [
    "## CORPUS (2)\n",
    "\n",
    "The sequence of word tokens in the corpus, indexed by their location in the corpus and document structures.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/dcb5rsj5ikteuch0bmu79gnp3p0x7o6u\n",
    "- GitHub URL for notebook used to create: https://github.com/mtvaden1/Text_Analytics_Final_Project/blob/main/Load_Song_Corpus.ipynb\n",
    "- Delimitter: **,**\n",
    "- Number of observations Between (should be >= 500,000 and <= 2,000,000 observations.): **207176** (got approval from Professor)\n",
    "- OHCO Structure (as delimitted column names): \n",
    "\n",
    "**['decade_id', 'song_num', 'stanza_num', 'line_num', 'token_num']**\n",
    "\n",
    "- Columns (as delimitted column names, including `token_str`, `term_str`, `pos`, and `pos_group`):\n",
    "\n",
    "**['pos_tuple', 'pos', 'token_str', 'term_str', 'pos_group']**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ae3214e-e6dd-42d6-842f-555d0058986e",
   "metadata": {},
   "source": [
    "## VOCAB (2)\n",
    "\n",
    "The unique word types (terms) in the corpus.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/14hmeklg9j5q5719k9gs8trj90nnr1mr\n",
    "- GitHub URL for notebook used to create: https://github.com/mtvaden1/Text_Analytics_Final_Project/blob/main/Load_Song_Corpus.ipynb and https://github.com/mtvaden1/Text_Analytics_Final_Project/blob/main/Compute_Derived_Tables.ipynb (to add dfidf)\n",
    "- Delimitter: **,**\n",
    "- Number of observations: **8975**\n",
    "- Columns (as delimitted names, including `n`, `p`', `i`, `dfidf`, `porter_stem`, `max_pos` and `max_pos_group`, `stop`):\n",
    "\n",
    "**['term_str', 'n', 'n_chars', 'p', 'i', 'max_pos', 'max_pos_group', 'stop', 'dfidf']**\n",
    "\n",
    "- Note: Your VOCAB may contain ngrams. If so, add a feature for `ngram_length`.\n",
    "- List the top 20 significant words in the corpus by DFIDF.\n",
    "\n",
    "**['1',\n",
    " 'ridin',\n",
    " 'extra',\n",
    " 'ey',\n",
    " 'roamin',\n",
    " 'buzz',\n",
    " 'buying',\n",
    " 'timeless',\n",
    " 'roadside',\n",
    " 'rivers',\n",
    " 'butter',\n",
    " 'rises',\n",
    " 'facts',\n",
    " 'ting',\n",
    " 'rips',\n",
    " 'faded',\n",
    " 'fags',\n",
    " 'fail',\n",
    " 'bursting',\n",
    " 'rights']**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b40dabdc-baae-4408-95bc-2f735824d59b",
   "metadata": {},
   "source": [
    "# Derived Tables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49f2ef9c-1cb5-41e8-a5ee-1e37428b4539",
   "metadata": {},
   "source": [
    "## BOW (3)\n",
    "\n",
    "A bag-of-words representation of the CORPUS.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/itgetr7qm86iwe78knkqokytyi5fpwec\n",
    "- GitHub URL for notebook used to create: https://github.com/mtvaden1/Text_Analytics_Final_Project/blob/main/Compute_Derived_Tables.ipynb\n",
    "- Delimitter: **,**\n",
    "- Bag (expressed in terms of OHCO levels): **['decade_id']**\n",
    "- Number of observations: **17678**\n",
    "- Columns (as delimitted names, including `n`, `tfidf`):\n",
    "\n",
    "**['decade_id', 'term_str', 'n', 'tfidf'] where 'decade_id' and 'term_str' are indices**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29890d2f-bf96-43ad-8d08-792393830163",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DTM (3)\n",
    "\n",
    "A represenation of the BOW as a sparse count matrix.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/6fr36v9z0wotx9o87quv3lzfd746eqz9\n",
    "- UVA Box URL of BOW used to generate (if applicable): https://virginia.box.com/s/itgetr7qm86iwe78knkqokytyi5fpwec\n",
    "- GitHub URL for notebook used to create: https://github.com/mtvaden1/Text_Analytics_Final_Project/blob/main/Compute_Derived_Tables.ipynb\n",
    "- Delimitter: **,**\n",
    "- Bag (expressed in terms of OHCO levels): **['decade_id']**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b4b4774-7c76-401d-a9de-2704f28a0821",
   "metadata": {},
   "source": [
    "## TFIDF (3)\n",
    "\n",
    "A Document-Term matrix with TFIDF values.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/zxk8sd35ny6e861h8dyqcgn8ao7daxlr\n",
    "- UVA Box URL of DTM or BOW used to create: https://virginia.box.com/s/itgetr7qm86iwe78knkqokytyi5fpwec\n",
    "- GitHub URL for notebook used to create: https://github.com/mtvaden1/Text_Analytics_Final_Project/blob/main/Compute_Derived_Tables.ipynb\n",
    "- Delimitter: **,**\n",
    "- Description of TFIDF formula ($\\LaTeX$ OK): \n",
    "\n",
    "$\\text{TF-IDF}(t, d, D) = \\text{TF}(t, d) \\times \\text{IDF}(t, D)$\n",
    "\n",
    "where $t$ represents a word in the document (in this case a given decade playlist), $d$ represents a document (decade playlist), and $D$ is a collection of documents (decade playlists).\n",
    "\n",
    "$TF(t,d)$ is the term frequency of word $t$ in document (decade playlist) $d$, calculated based on the **max** $TF$ method. $IDF(t,D)$ is the inverse document frequency of term $t$ in the $D$, calculated based on the **standard** $IDF$ method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd34f5ca-5361-4701-b9dd-9da66859b40b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reduced and Normalized TFIDF_L2 (3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c548dd2-f692-4365-936c-39c84df79b90",
   "metadata": {
    "tags": []
   },
   "source": [
    "A Document-Term matrix with L2 normalized TFIDF values.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/bcg6i25y0hf00np7vfk5s2tbj7do2uen\n",
    "- UVA Box URL of source TFIDF table: https://virginia.box.com/s/zxk8sd35ny6e861h8dyqcgn8ao7daxlr\n",
    "- GitHub URL for notebook used to create: https://github.com/mtvaden1/Text_Analytics_Final_Project/blob/main/Compute_Derived_Tables.ipynb\n",
    "- Delimitter: **,**\n",
    "- Number of features (i.e. significant words): **5000**\n",
    "- Principle of significant word selection: **Here, the principle of significant word selection meant only including nouns, verbs, and adjectives, with the assumption that these parts of speech are more relevant and informative for the task. I also excluded proper nouns, since they are specific entity names and are not likely to contribute to the analysis. Finally, I took the top 5000 words as sorted by DFIDF to make a more manageable dataset.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c50da94-af36-4e8d-b1a7-24dbcf431880",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9df79264-dd93-4199-be38-db31579b7ce8",
   "metadata": {},
   "source": [
    "## PCA Components (4)\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/6p28lg9wodtllsvvxh21jt52nlrcem9j\n",
    "- UVA Box URL of the source TFIDF_L2 table: https://virginia.box.com/s/bcg6i25y0hf00np7vfk5s2tbj7do2uen\n",
    "- GitHub URL for notebook used to create: https://github.com/mtvaden1/Text_Analytics_Final_Project/blob/main/Models.ipynb\n",
    "- Delimitter: **,**\n",
    "- Number of components: **6**\n",
    "- Library used to generate: **sklearn PCA**\n",
    "- Top 5 positive terms for first component:\n",
    "\n",
    "**['eheu', 'para', 'que', 'nanananana', 'ahah']**\n",
    "\n",
    "- Top 5 negative terms for second component:\n",
    "\n",
    "**['dun', 'earn', 'tonights', 'dit', 'nyu']**\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73adc882-cbce-4d24-9923-5d36ac609f43",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PCA DCM (4)\n",
    "\n",
    "The document-component matrix generated.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/gncxsnj9a294np1xiig8hthny6iotu79\n",
    "- GitHub URL for notebook used to create: https://github.com/mtvaden1/Text_Analytics_Final_Project/blob/main/Models.ipynb\n",
    "- Delimitter: **,**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3fd2a4a-7f2f-4259-a5c4-063168cb1b14",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PCA Loadings (4)\n",
    "\n",
    "The component-term matrix generated.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/t8xhl7fu8xxzzalj0r00xuutpmyjbe41\n",
    "- GitHub URL for notebook used to create: https://github.com/mtvaden1/Text_Analytics_Final_Project/blob/main/Models.ipynb\n",
    "- Delimitter: **,**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84fff42f-6665-4941-ba3d-034627dc0124",
   "metadata": {},
   "source": [
    "## PCA Visualization 1 (4)\n",
    "\n",
    "Include a scatterplot of documents in the space created by the first two components.\n",
    "\n",
    "Color the points based on a metadata feature associated with the documents.\n",
    "\n",
    "Also include a scatterplot of the loadings for the same two components. (This does not need a feature mapped onto color.)\n",
    "\n",
    "![](DS5001_Plots/PCA_Vis1a1.png)\n",
    "\n",
    "![](DS5001_Plots/PCA_Vis1b.png)\n",
    "\n",
    "Briefly describe the nature of the polarity you see in the first component:\n",
    "\n",
    "**When describing the graph of the documents in space that is created by the first two components, what really strikes me is that the first component really effectively separates the decades over time. Specifically, we see that the 70s, 80s, and 90s are are negative for the first component, while the 2000s, 2010s, and 2020s are all positive. Interestingly, the first component also does a good job of showing loudness, which shows a natural trend over time with the decades. The 70s and 80s have the lowest loudness, with an increase in the 90s. The 2000s have the highest loudness, followed by the 2010s and 2020s. The loadings also show a little bit of information with the words, with a lot of the negative words (or sounds, which are captured in the lyrics) being more rhythmic. The positive words appear more loud or energetic, with some onomatopoetic representing louder (or screaming) noises**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2eb54565-7669-4a2f-90b2-a4c283277c02",
   "metadata": {},
   "source": [
    "## PCA Visualization 2 (4)\n",
    "\n",
    "Include a scatterplot of documents in the space created by the second two components.\n",
    "\n",
    "Color the points based on a metadata feature associated with the documents.\n",
    "\n",
    "Also include a scatterplot of the loadings for the same two components. (This does not need a feature mapped onto color.)\n",
    "\n",
    "![](DS5001_Plots/PCA_Vis2a2.png)\n",
    "\n",
    "![](DS5001_Plots/PCA_Vis2b.png)\n",
    "\n",
    "**The graphs of the second component pair well with the acousticness of each decade as shown on the graph of the document space between the second two components. The positive documents for the second component appear to be much more acoustic than the negative documents, with the 2020s and 70s being the most acoustic. The 90s and 2000s are the least acoustic, and are the most negative documents for the second component. The loadings also show that words such as jam and jamming, which can relate to acoustic guitars and other similar instruments, are positive. In constrast, the negative loadings for the second component such as the onomatopoetic words woohoo, nyu, and dun relate more to electronic or synthetic sounds**\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d3ee23b2-25d1-4226-bf31-1607e5ed4677",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LDA TOPIC (4)\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/orbt496o1qchrfydrqdjzpwk35wh0huh\n",
    "- UVA Box URL of count matrix used to create: https://virginia.box.com/s/r3o925jentm48xq4k89zyv6srxgq3ex4\n",
    "- GitHub URL for notebook used to create: https://github.com/mtvaden1/Text_Analytics_Final_Project/blob/main/Models.ipynb\n",
    "- Delimitter: **,**\n",
    "- Libary used to compute: **sklearn decomposition LDA**\n",
    "- A description of any filtering, e.g. POS (Nouns and Verbs only): **Only the length of strings of song lyrics > 1, no parts of speech. Results were similar regardless**\n",
    "- Number of components: **20**\n",
    "- Any other parameters used: \n",
    "\n",
    "ngram_range = (1, 2),\n",
    "n_terms = 4000,\n",
    "n_topics = 20,\n",
    "max_iter = 20,\n",
    "n_top_terms = 8\n",
    "\n",
    "- Top 5 words and best-guess labels for topic five topics by mean document weight:\n",
    "  - T00: **\"yeah yeah yeah just na dont im love na na\"** -> sing-along topic\n",
    "  - T01: **\"love know im dont oh ill like got\"** -> love and uncertainty\n",
    "  - T02: **\"hey oh hey hey im dont oh oh baby yeah\"** -> pursuing love\n",
    "  - T03: **\"way got just dont youre want light hold\"** -> more romantic and wholesome\n",
    "  - T04: **\"im dont yeah got ill feel oh just\"** -> more uncertainty"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a518d520-4a5c-48fa-836d-f8ea3e3c2f06",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LDA THETA (4)\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/2xi2k0hir5gwr9wmzvgxdtvxozx82so3\n",
    "- GitHub URL for notebook used to create: https://github.com/mtvaden1/Text_Analytics_Final_Project/blob/main/Models.ipynb\n",
    "- Delimitter: **,**,"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8808b30-64f4-4249-95d5-d7c0925ce432",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LDA PHI (4)\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/5zphu4855l8kfwsbzvqipyvr3sb2nktu\n",
    "- GitHub URL for notebook used to create: https://github.com/mtvaden1/Text_Analytics_Final_Project/blob/main/Models.ipynb\n",
    "- Delimitter: **,**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18e404bf-8a2a-4eb4-ba89-0c708c8f359d",
   "metadata": {},
   "source": [
    "## LDA + PCA Visualization (4)\n",
    "\n",
    "Apply PCA to the PHI table and plot the topics in the space opened by the first two components.\n",
    "\n",
    "Size the points based on the mean document weight of each topic (using the THETA table).\n",
    "\n",
    "Provide a brief interpretation of what you see.\n",
    "\n",
    "![](DS5001_Plots/LDA_PCA_labeled.png)\n",
    "\n",
    "**After looking at the plot of the topics in space for the first two components, what I can interpret is that the first component seems to separate the topics by sound uncertainty. Love and dancing are the complete overarching themes here (as is mostly true in music), but the negative documents in the first component show words that demonstrate a lot more uncertainty and clear want of intimacy. These topics have the highest document weights and frequency when compared to the positive documents for the first component, which are sparse and either onomatopoetic in representing electronic dance music (beep, dun, nyu, la), or more focused on pleasure.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7e1f327-a386-476a-8d94-2ab7a63afa7a",
   "metadata": {},
   "source": [
    "## Sentiment VOCAB_SENT (4)\n",
    "\n",
    "Sentiment values associated with a subset of the VOCAB from a curated sentiment lexicon.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/6rny0du981ke0283jn0o8kb566i3axtg\n",
    "- UVA Box URL for source lexicon: https://virginia.box.com/s/482z365s0o71ga9sgfwx1lkffrixlsoq\n",
    "- GitHub URL for notebook used to create: https://github.com/mtvaden1/Text_Analytics_Final_Project/blob/main/Models.ipynb\n",
    "- Delimitter: **,**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa8a9d67-1560-4be9-b82a-b99a60b5c93e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sentiment BOW_SENT (4)\n",
    "\n",
    "Sentiment values from VOCAB_SENT mapped onto BOW.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/g7jkjr16diiz4x7d2lkvb30c8ge9x1fu\n",
    "- GitHub URL for notebook used to create: https://github.com/mtvaden1/Text_Analytics_Final_Project/blob/main/Models.ipynb\n",
    "- Delimitter: **,**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6ee6837-b12e-453d-96c1-59eaa4b28883",
   "metadata": {},
   "source": [
    "## Sentiment DOC_SENT (4)\n",
    "\n",
    "Computed sentiment per bag computed from BOW_SENT.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/bjfvug1sd3oszs4qdpzxyhv8bm55s7nl\n",
    "- GitHub URL for notebook used to create: https://github.com/mtvaden1/Text_Analytics_Final_Project/blob/main/Models.ipynb\n",
    "- Delimitter: **,**\n",
    "- Document bag expressed in terms of OHCO levels: **['decade_id']**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e4cba13-e60a-4940-a06d-02479f002c3c",
   "metadata": {},
   "source": [
    "## Sentiment Plot (4)\n",
    "\n",
    "Plot sentiment over some metric space, such as time.\n",
    "\n",
    "If you don't have a metric metadata features, plot sentiment over a feature of your choice.\n",
    "\n",
    "You may use a bar chart or a line graph.\n",
    "\n",
    "![](DS5001_Plots/emo_sentiments.png)\n",
    "\n",
    "![](DS5001_Plots/emo_general_sentiment.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f5d2316-317b-4d95-a804-aff98242e411",
   "metadata": {},
   "source": [
    "## VOCAB_W2V (4)\n",
    "\n",
    "A table of word2vec features associated with terms in the VOCAB table.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/zdjw4egbbmptd28xqa673i9d4owfbz4q\n",
    "- GitHub URL for notebook used to create: https://github.com/mtvaden1/Text_Analytics_Final_Project/blob/main/Models.ipynb\n",
    "- Delimitter: **,**\n",
    "- Document bag expressed in terms of OHCO levels: **['term_str]**\n",
    "- Number of features generated: **246**\n",
    "- The library used to generate the embeddings: **gensim word2vec**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "833c1974-047b-4285-9f4d-7f3314f39542",
   "metadata": {},
   "source": [
    "## Word2vec tSNE Plot (4)\n",
    "\n",
    "Plot word embedding featues in two-dimensions using t-SNE.\n",
    "\n",
    "Describe a cluster in the plot that captures your attention.\n",
    "\n",
    "![](DS5001_plots/tSNE.png)\n",
    "\n",
    "![](DS5001_plots/w2v_cluster.png)\n",
    "\n",
    "**Looking at the entire shape of the TSNE plot, I thought that the shape was very interesting and non-linear. However, one cluster that really caught my attention when zoomed in (second photo) is at the bottom right of the plot, with a high positive x value and negative y value. Some of the words we see here are sky, bright, lord, heart, dream, moonlight, star, dream, hallelujah, music, and dancing. This was a very interesting cluster as it is an intersection of music, nature, mystery, and religion. This cluster in totality feels very ethereal, optimistic, and surreal.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75878341-7fe8-4e22-b908-36029f9818e8",
   "metadata": {},
   "source": [
    "# Riffs\n",
    "\n",
    "Provde at least three visualizations that combine the preceding model data in interesting ways.\n",
    "\n",
    "These should provide insight into how features in the LIB table are related. \n",
    "\n",
    "The nature of this relationship is left open to you -- it may be correlation, or mutual information, or something less well defined. \n",
    "\n",
    "In doing so, consider the following visualization types:\n",
    "\n",
    "- Hierarchical cluster diagrams\n",
    "- Heatmaps\n",
    "- Scatter plots\n",
    "- KDE plots\n",
    "- Dispersion plots\n",
    "- t-SNE plots\n",
    "- etc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c62acf1-6bb0-45d0-aed2-863b285f8cad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Riff 1 (5)\n",
    "\n",
    "### LDA + PCA Visualization combined with LIB table to see decade with highest weight\n",
    "\n",
    "![](DS5001_plots/Riff1_updated.png)\n",
    "\n",
    "**This visualization was my first Riff based on the initial instructions to combine the LDA and PCA Visualization with metadata from the lib table, which felt very difficult based on the indices of the data. However, here I was able to uses the Theta table to discover which decade from the LIB table had the highest document weight for each of the topics, which I then joined with the DCM and TOPICS tables. Here we can see that the 2020s have the highest document-weighted topics, corresponding to the topics of uncertainty and intimacy shown from the earlier LDA PCA visualization. We can see that here that the topics that are most strongly influenced by the 90s and 2000s are also grouped more concisely within the first component on the plot, with the topics most heavily influenced by the 2010s decade being the most sporadic.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2155a072-02b3-4aa8-b9f1-e43a59e9a85d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Riff 2 (5)\n",
    "\n",
    "### Euclidean - Average Hierarchical Cluster\n",
    "\n",
    "![](DS5001_plots/Riff2_hc1.png)\n",
    "\n",
    "\n",
    "**Looking at the hierarchical clustering using Euchlidean Distance and the average linkage method, we can see that the decades are separated in roughly chronological order. Euclidean distance separates the 70s and the 90s lyrics recommended from Spotify from the rest of the decades, followed by the 80s, then 2020s, then 2000s and 2010s. This intuitively makes sense over time that each decade is clustered with decades that precede or follow it, although it is interesting that the 2000s and 2010s are considered to be the most similar and the 80s are colored along with the 2000, 10s, and 20s rather than the 70s and 90s. This could be reflective of my personalized taste in the alternative and rock genres from the 80s, as well as my taste for alternative rock from current artists.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5067c59b-8983-4acc-972a-1ecd852ded57",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Riff 3 (5)\n",
    "\n",
    "### Heatmap of Probabilistic TFIDF over the Decades for Sample Words\n",
    "\n",
    "![](DS5001_plots/Riff3a.png)\n",
    "\n",
    "### TFIDF per Decade for Example Words\n",
    "\n",
    "*Apologies for the explicit words here, but I actually thought the conclusions were pretty meaningful*\n",
    "\n",
    "![](DS5001_plots/Riff3b.png)\n",
    "![](DS5001_plots/Riff3c.png)\n",
    "![](DS5001_plots/Riff3d.png)\n",
    "![](DS5001_plots/Riff3e.png)\n",
    "\n",
    "**When examining the heatmap of probabilistic TFIDF over the decades for this given list of sample words, a few things stood out to me. The biggest thing is the change in TFIDF of these words over time, which we can examine by looking at the gradient per decade. Some familial and traditional themes such as husband and wife are more present in the 70s and 80s, as well as folk and country music words such as country, guitar, and beer. The most interesting of these sample words to me is violence, which appears to increase steadily in TFIDF over each decade until 2020, when it suddenly disappears completely. Additionally, both peace and stress also become more prevalent as violence increases, representing potential political and ideological extremes which may have grown over time in modern music that is catered to my taste.**\n",
    "\n",
    "**I also included these plots of TFIDF per Decade for some specific words because the conclusions were so interesting. All of the themes of alcohol, violence, sex, and swearing appear to have generally grown over time in the music data here. These controversal topics are shown by the data to have become more prominent in the 21st century, especially with the use of more expletives and alcohol/substance abuse in the 2020s. One explanation for this trend could be because I listen to more current rap music and tend to listen to older classic rock, as rap music can have more extreme and controversial lyrics.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68e25c6e-2624-4899-829e-e7d60c878685",
   "metadata": {},
   "source": [
    "# Interpretation (4)\n",
    "\n",
    "Describe something interesting about your corpus that you discovered during the process of completing this assignment.\n",
    "\n",
    "At a minumum, use 250 words, but you may use more. You may also add images if you'd like.\n",
    "\n",
    "### Hierarchical Agglomerative Cluster Tree of Vector Space\n",
    "\n",
    "![](DS5001_plots/Riff4.png)\n",
    "\n",
    "**I wanted to start off my final interpretation with this HAC because I think it relates to a theme that I found a lot in my PCA and LDA sections of my project. After talking about the separation of onomatopoetic words that describe rhythm or dance music lyrics from other english words in the principle components earlier in this project, we can see that these onomatopoetic and shouting style words (lo, hey, lala, li) are the first to be separated in our HAC. Additionally, we can see that the next split also concerns a previous observation, where words that are related to desire and uncertainty (can, can't, want, give) are separated next. This trend reflects the themes that I noticed in the principle component analysis based on the loadings that were separated by the first and second princple components.**\n",
    "\n",
    "**Beyond the onomatopoetic/shouting and uncertainty themes that were very prevalant in my analysis, I was surprised by how all of my topics were about love in some way. I know that most of music is about love, but this still exceeded my expectations.**\n",
    "\n",
    "**Finally, I thought that all of the metadata and lyrical trends that evolved over time in each decade were very interesting. It made sense to me that loudness increased in music over time, and acousticness general decreased (except for my love of 2020s alternative and indie music). However, I thought it was very suprising that all of my music recommendations in each decade had relatively negative sentiment. I was not surprised to see that the 70s and 80s had the most positive sentiment for me, but this project has helped me become more aware of how sad the music I listen to may be, as that can often have an effect on my mood. Lastly, the increase in expletives and controversial lyrics about violence, love, and substance abuse over time does not surprise me, as I feel like mental health concerns and addictions are more public and open-addressed than ever in both music and society as a whole. I really enjoyed doing this project and feel like I learned a lot about the challenges of working with lyrics that do not form full sentences or are very repetitive, but I also feel like I learned some about myself. Part of me wishes that there were Spotify playlists available for each decade that did not take my current listening preferences into account so that I could better generalize my findings, but I am extremely satisfied to have a lot to think about each time I listen to a song going forward.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
